{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6adc9be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\S'\n",
      "C:\\Users\\dhany\\AppData\\Local\\Temp\\ipykernel_17432\\350215933.py:4: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  crop_df = pd.read_csv(\"datasets\\crop.csv\")\n",
      "C:\\Users\\dhany\\AppData\\Local\\Temp\\ipykernel_17432\\350215933.py:5: SyntaxWarning: invalid escape sequence '\\S'\n",
      "  imd_df = pd.read_csv(\"datasets\\Sub_Division_IMD_2017.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 3730 rows with missing 'Production'.\n",
      "Removed 3523 rows with Area > 0 but Production = 0.\n",
      "Final size of cleaned crop data: 238838 rows.\n",
      "\n",
      "Missing values in rainfall data imputed using the median for each column.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dhany\\AppData\\Local\\Temp\\ipykernel_17432\\350215933.py:51: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  imd_df_cleaned[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\dhany\\AppData\\Local\\Temp\\ipykernel_17432\\350215933.py:51: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  imd_df_cleaned[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\dhany\\AppData\\Local\\Temp\\ipykernel_17432\\350215933.py:51: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  imd_df_cleaned[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\dhany\\AppData\\Local\\Temp\\ipykernel_17432\\350215933.py:51: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  imd_df_cleaned[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\dhany\\AppData\\Local\\Temp\\ipykernel_17432\\350215933.py:51: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  imd_df_cleaned[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\dhany\\AppData\\Local\\Temp\\ipykernel_17432\\350215933.py:51: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  imd_df_cleaned[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\dhany\\AppData\\Local\\Temp\\ipykernel_17432\\350215933.py:51: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  imd_df_cleaned[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\dhany\\AppData\\Local\\Temp\\ipykernel_17432\\350215933.py:51: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  imd_df_cleaned[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\dhany\\AppData\\Local\\Temp\\ipykernel_17432\\350215933.py:51: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  imd_df_cleaned[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\dhany\\AppData\\Local\\Temp\\ipykernel_17432\\350215933.py:51: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  imd_df_cleaned[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\dhany\\AppData\\Local\\Temp\\ipykernel_17432\\350215933.py:51: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  imd_df_cleaned[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\dhany\\AppData\\Local\\Temp\\ipykernel_17432\\350215933.py:51: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  imd_df_cleaned[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\dhany\\AppData\\Local\\Temp\\ipykernel_17432\\350215933.py:51: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  imd_df_cleaned[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\dhany\\AppData\\Local\\Temp\\ipykernel_17432\\350215933.py:51: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  imd_df_cleaned[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\dhany\\AppData\\Local\\Temp\\ipykernel_17432\\350215933.py:51: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  imd_df_cleaned[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\dhany\\AppData\\Local\\Temp\\ipykernel_17432\\350215933.py:51: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  imd_df_cleaned[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\dhany\\AppData\\Local\\Temp\\ipykernel_17432\\350215933.py:51: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  imd_df_cleaned[col].fillna(median_val, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cleaning Complete ---\n",
      "Cleaned crop data saved to 'crop_cleaned.csv'\n",
      "Cleaned rainfall data saved to 'rainfall_cleaned.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "crop_df = pd.read_csv(\"datasets\\crop.csv\")\n",
    "imd_df = pd.read_csv(\"datasets\\Sub_Division_IMD_2017.csv\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. Cleaning the Crop Production Data (crop_df)\n",
    "# ==============================================================================\n",
    "\n",
    "# 1.1 Handle missing 'Production' values by dropping rows\n",
    "# Dropping is preferred over imputation for production quantity due to high variability.\n",
    "rows_before = len(crop_df)\n",
    "crop_df_cleaned = crop_df.dropna(subset=['Production']).copy()\n",
    "rows_dropped = rows_before - len(crop_df_cleaned)\n",
    "print(f\"Removed {rows_dropped} rows with missing 'Production'.\")\n",
    "\n",
    "# 1.2 Ensure 'Production' is numeric (although it was float64, this step is good practice)\n",
    "crop_df_cleaned['Production'] = pd.to_numeric(\n",
    "    crop_df_cleaned['Production'], errors='coerce'\n",
    ")\n",
    "crop_df_cleaned.dropna(subset=['Production'], inplace=True)\n",
    "\n",
    "\n",
    "# 1.3 Handle logical inconsistencies: Area > 0 but Production = 0\n",
    "# These rows often represent crop failures or data entry errors and are removed for robust analysis.\n",
    "inconsistent_rows = crop_df_cleaned[\n",
    "    (crop_df_cleaned['Area'] > 0) & (crop_df_cleaned['Production'] == 0)\n",
    "]\n",
    "inconsistent_count = len(inconsistent_rows)\n",
    "\n",
    "crop_df_cleaned = crop_df_cleaned[\n",
    "    ~((crop_df_cleaned['Area'] > 0) & (crop_df_cleaned['Production'] == 0))\n",
    "].copy()\n",
    "\n",
    "print(f\"Removed {inconsistent_count} rows with Area > 0 but Production = 0.\")\n",
    "print(f\"Final size of cleaned crop data: {len(crop_df_cleaned)} rows.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. Cleaning the Rainfall Data (imd_df)\n",
    "# ==============================================================================\n",
    "\n",
    "# 2.1 Impute missing values in rainfall columns\n",
    "# Rainfall columns start from index 2 ('JAN') to the end.\n",
    "rain_cols = imd_df.columns[2:]\n",
    "\n",
    "# Use the median for imputation as it is robust to extreme rainfall outliers.\n",
    "imd_df_cleaned = imd_df.copy()\n",
    "for col in rain_cols:\n",
    "    median_val = imd_df_cleaned[col].median()\n",
    "    imd_df_cleaned[col].fillna(median_val, inplace=True)\n",
    "\n",
    "print(\"\\nMissing values in rainfall data imputed using the median for each column.\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. Save the cleaned datasets\n",
    "# ==============================================================================\n",
    "crop_df_cleaned.to_csv(\"crop_cleaned.csv\", index=False)\n",
    "imd_df_cleaned.to_csv(\"rainfall_cleaned.csv\", index=False)\n",
    "\n",
    "print(\"\\n--- Cleaning Complete ---\")\n",
    "print(\"Cleaned crop data saved to 'crop_cleaned.csv'\")\n",
    "print(\"Cleaned rainfall data saved to 'rainfall_cleaned.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16f24659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the cleaned datasets\n",
    "crop_df = pd.read_csv(\"datasets/crop_cleaned.csv\")\n",
    "rainfall_df = pd.read_csv(\"datasets/rainfall_cleaned.csv\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. Define the Mapping for State_Name to SUBDIVISION\n",
    "# ==============================================================================\n",
    "\n",
    "# This dictionary maps a State/UT name (from crop data) to the list of\n",
    "# meteorological sub-divisions (from rainfall data) it covers.\n",
    "state_to_subdivision_map = {\n",
    "    'Andaman and Nicobar Islands': ['Andaman & Nicobar Islands'],\n",
    "    'Andhra Pradesh': ['Coastal Andhra Pradesh', 'Rayalseema'],\n",
    "    'Arunachal Pradesh': ['Arunachal Pradesh'],\n",
    "    'Assam': ['Assam & Meghalaya'],\n",
    "    'Bihar': ['Bihar'],\n",
    "    'Chandigarh': ['Haryana Delhi & Chandigarh'],\n",
    "    'Chhattisgarh': ['Chhattisgarh'],\n",
    "    'Dadra and Nagar Haveli': ['Gujarat Region', 'Saurashtra & Kutch'],\n",
    "    'Goa': ['Konkan & Goa'],\n",
    "    'Gujarat': ['Gujarat Region', 'Saurashtra & Kutch'],\n",
    "    'Haryana': ['Haryana Delhi & Chandigarh'],\n",
    "    'Himachal Pradesh': ['Himachal Pradesh'],\n",
    "    'Jammu and Kashmir': ['Jammu & Kashmir'],\n",
    "    'Jharkhand': ['Jharkhand'],\n",
    "    'Karnataka': ['Coastal Karnataka', 'North Interior Karnataka', 'South Interior Karnataka'],\n",
    "    'Kerala': ['Kerala'],\n",
    "    'Madhya Pradesh': ['East Madhya Pradesh', 'West Madhya Pradesh'],\n",
    "    'Maharashtra': ['Konkan & Goa', 'Madhya Maharashtra', 'Matathwada', 'Vidarbha'],\n",
    "    'Manipur': ['Naga Mani Mizo Tripura'],\n",
    "    'Meghalaya': ['Assam & Meghalaya'],\n",
    "    'Mizoram': ['Naga Mani Mizo Tripura'],\n",
    "    'Nagaland': ['Naga Mani Mizo Tripura'],\n",
    "    'Odisha': ['Orissa'],\n",
    "    'Puducherry': ['Tamil Nadu'],\n",
    "    'Punjab': ['Punjab'],\n",
    "    'Rajasthan': ['East Rajasthan', 'West Rajasthan'],\n",
    "    'Sikkim': ['Sub Himalayan West Bengal & Sikkim'],\n",
    "    'Tamil Nadu': ['Tamil Nadu'],\n",
    "    'Telangana': ['Telangana'],\n",
    "    'Tripura': ['Naga Mani Mizo Tripura'],\n",
    "    'Uttar Pradesh': ['East Uttar Pradesh', 'West Uttar Pradesh'],\n",
    "    'Uttarakhand': ['Uttarakhand'],\n",
    "    'West Bengal': ['Gangetic West Bengal', 'Sub Himalayan West Bengal & Sikkim']\n",
    "}\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. Pre-processing the Crop Data for Merging\n",
    "# ==============================================================================\n",
    "\n",
    "# 2.1 Clean State Names and create a list of subdivisions for each crop row\n",
    "crop_df['State_Name'] = crop_df['State_Name'].str.strip()\n",
    "crop_df['SUBDIVISION_List'] = crop_df['State_Name'].map(state_to_subdivision_map)\n",
    "\n",
    "# 2.2 Explode the DataFrame and rename columns for merging\n",
    "# This step creates multiple rows for states that span multiple rainfall sub-divisions.\n",
    "crop_df_expanded = crop_df.explode('SUBDIVISION_List').rename(\n",
    "    columns={'SUBDIVISION_List': 'SUBDIVISION', 'Crop_Year': 'YEAR'}\n",
    ")\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. Merging the Datasets\n",
    "# ==============================================================================\n",
    "\n",
    "# 3.1 Perform the inner merge on both YEAR and SUBDIVISION\n",
    "integrated_df = pd.merge(\n",
    "    crop_df_expanded,\n",
    "    rainfall_df,\n",
    "    on=['YEAR', 'SUBDIVISION'],\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# 3.2 Calculate Yield (Production per Area)\n",
    "integrated_df['Yield (Production/Area)'] = integrated_df['Production'] / integrated_df['Area']\n",
    "\n",
    "# Save the final integrated dataset\n",
    "integrated_df.to_csv(\"crop_rainfall_integrated.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5852611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded datasets/crop_rainfall_integrated_cleaned.csv. DataFrame shape: (412295, 27)\n",
      "Successfully connected to the database: samarth_agri_climate.db\n",
      "Successfully inserted data into table: integrated_data\n",
      "\n",
      "Verification: Data read back from the database:\n",
      "                         state  district  year       season  \\\n",
      "0  andaman and nicobar islands  NICOBARS  2000  Kharif        \n",
      "1  andaman and nicobar islands  NICOBARS  2000  Kharif        \n",
      "2  andaman and nicobar islands  NICOBARS  2000  Kharif        \n",
      "3  andaman and nicobar islands  NICOBARS  2000  Whole Year    \n",
      "4  andaman and nicobar islands  NICOBARS  2000  Whole Year    \n",
      "\n",
      "                  crop  area_ha  production_tonnes  \\\n",
      "0             Arecanut   1254.0             2000.0   \n",
      "1  Other Kharif pulses      2.0                1.0   \n",
      "2                 Rice    102.0              321.0   \n",
      "3               Banana    176.0              641.0   \n",
      "4            Cashewnut    720.0              165.0   \n",
      "\n",
      "                   subdivision   jan   feb  ...    oct    nov    dec  \\\n",
      "0  andaman and nicobar islands  53.0  59.0  ...  321.2  158.3  115.2   \n",
      "1  andaman and nicobar islands  53.0  59.0  ...  321.2  158.3  115.2   \n",
      "2  andaman and nicobar islands  53.0  59.0  ...  321.2  158.3  115.2   \n",
      "3  andaman and nicobar islands  53.0  59.0  ...  321.2  158.3  115.2   \n",
      "4  andaman and nicobar islands  53.0  59.0  ...  321.2  158.3  115.2   \n",
      "\n",
      "   annual_rainfall_mm     jf    mam    jjas    ond  yield_t_per_ha  \\\n",
      "0              2763.2  112.0  812.2  1244.2  594.7        1.594896   \n",
      "1              2763.2  112.0  812.2  1244.2  594.7        0.500000   \n",
      "2              2763.2  112.0  812.2  1244.2  594.7        3.147059   \n",
      "3              2763.2  112.0  812.2  1244.2  594.7        3.642045   \n",
      "4              2763.2  112.0  812.2  1244.2  594.7        0.229167   \n",
      "\n",
      "               state_canonical  \n",
      "0  andaman and nicobar islands  \n",
      "1  andaman and nicobar islands  \n",
      "2  andaman and nicobar islands  \n",
      "3  andaman and nicobar islands  \n",
      "4  andaman and nicobar islands  \n",
      "\n",
      "[5 rows x 27 columns]\n",
      "\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "# --- Configuration ---\n",
    "csv_file = 'datasets/crop_rainfall_integrated_cleaned.csv'\n",
    "db_file = 'samarth_agri_climate.db'\n",
    "table_name = 'integrated_data'\n",
    "\n",
    "# --- 1. Load the CSV data into a Pandas DataFrame ---\n",
    "try:\n",
    "    df = pd.read_csv(csv_file)\n",
    "    print(f\"Successfully loaded {csv_file}. DataFrame shape: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file {csv_file} was not found.\")\n",
    "    exit()\n",
    "\n",
    "# --- 2. Create a database connection ---\n",
    "# This creates the SQLite database file if it doesn't exist.\n",
    "conn = sqlite3.connect(db_file)\n",
    "print(f\"Successfully connected to the database: {db_file}\")\n",
    "\n",
    "# --- 3. Use to_sql() to push the DataFrame content into the DB ---\n",
    "# if_exists='replace': Drops the table if it exists and creates a new one.\n",
    "# index=False: Prevents the DataFrame's index from becoming a column.\n",
    "df.to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "print(f\"Successfully inserted data into table: {table_name}\")\n",
    "\n",
    "# --- 4. Verification (Reading data back from the DB) ---\n",
    "query = f\"SELECT * FROM {table_name} LIMIT 5;\"\n",
    "df_from_db = pd.read_sql_query(query, conn)\n",
    "print(\"\\nVerification: Data read back from the database:\")\n",
    "print(df_from_db)\n",
    "\n",
    "# --- 5. Close the connection ---\n",
    "conn.close()\n",
    "print(\"\\nDatabase connection closed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
